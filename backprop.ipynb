{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ac93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[6,8,9],[7,9,9],[6,10,6],[5,12,7]], columns=['cgpa', 'profile_score', 'lpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8a7f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  lpa\n",
       "0     6              8    9\n",
       "1     7              9    9\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89bca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "  \n",
    "  np.random.seed(3)\n",
    "  parameters = {}\n",
    "  L = len(layer_dims)         \n",
    "\n",
    "  for l in range(1, L):\n",
    "\n",
    "    parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l]))*0.1\n",
    "    parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "      \n",
    "\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0512fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "  \n",
    "  Z = np.dot(W.T, A_prev) + b\n",
    "  \n",
    "  return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3eeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Prop\n",
    "def L_layer_forward(X, parameters):\n",
    "\n",
    "  A = X\n",
    "  L = len(parameters) // 2                  # number of layers in the neural network\n",
    "  \n",
    "  for l in range(1, L+1):\n",
    "    A_prev = A \n",
    "    Wl = parameters['W' + str(l)]\n",
    "    bl = parameters['b' + str(l)]\n",
    "    print(\"A\"+str(l-1)+\": \", A_prev)\n",
    "    print(\"W\"+str(l)+\": \", Wl)\n",
    "    print(\"b\"+str(l)+\": \", bl)\n",
    "    print(\"--\"*20)\n",
    "\n",
    "    A = linear_forward(A_prev, Wl, bl)\n",
    "    print(\"A\"+str(l)+\": \", A)\n",
    "    print(\"**\"*20)\n",
    "          \n",
    "  return A,A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a99a77f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[6]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.4]\n",
      " [1.4]]\n",
      "****************************************\n",
      "A1:  [[1.4]\n",
      " [1.4]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.28]]\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[0][0]\n",
    "\n",
    "# Parameter initialization\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19a0a762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.28]]),\n",
       " array([[1.4],\n",
       "        [1.4]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat,A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24da88b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588b6683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.28]]),\n",
       " array([[1.4],\n",
       "        [1.4]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c44e271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n",
    "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n",
    "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n",
    "\n",
    "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "304b7bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:2: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n",
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n",
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n",
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:11: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
      "C:\\Users\\kriti\\AppData\\Local\\Temp\\ipykernel_29848\\332058445.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0])\n"
     ]
    }
   ],
   "source": [
    "update_parameters(parameters,y,y_hat,A1,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0081d768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.11301889, 0.11735852],\n",
       "        [0.11301889, 0.11735852]]),\n",
       " 'b1': array([[0.00216982],\n",
       "        [0.00216982]]),\n",
       " 'W2': array([[0.124416],\n",
       "        [0.124416]]),\n",
       " 'b2': array([[0.141856]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09676bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.11301889 0.11735852]\n",
      " [0.11301889 0.11735852]]\n",
      "b1:  [[0.00216982]\n",
      " [0.00216982]]\n",
      "----------------------------------------\n",
      "A1:  [[1.81047206]\n",
      " [1.87990614]]\n",
      "****************************************\n",
      "A1:  [[1.81047206]\n",
      " [1.87990614]]\n",
      "W2:  [[0.124416]\n",
      " [0.124416]]\n",
      "b2:  [[0.141856]]\n",
      "----------------------------------------\n",
      "A2:  [[0.60099809]]\n",
      "****************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.13122454, 0.14076578],\n",
       "        [0.13136168, 0.14094211]]),\n",
       " 'b1': array([[0.00477062],\n",
       "        [0.00479021]]),\n",
       " 'W2': array([[0.15482832],\n",
       "        [0.15599467]]),\n",
       " 'b2': array([[0.17279267]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select one training example (row index = 1) from dataset\n",
    "\n",
    "# Step 1: Extract input features (cgpa & profile_score)\n",
    "# df[['cgpa', 'profile_score']] → select 2 columns as DataFrame\n",
    "# .values → convert to NumPy array\n",
    "# [1] → select second row (index starts at 0)\n",
    "# reshape(2,1) → convert shape from (2,) to (2,1)\n",
    "# Neural networks expect shape: (no_of_features, no_of_examples)\n",
    "X = df[['cgpa', 'profile_score']].values[1].reshape(2,1)\n",
    "\n",
    "\n",
    "# Step 2: Extract target value (lpa)\n",
    "# df[['lpa']] → select target column\n",
    "# .values → convert to NumPy array\n",
    "# [1] → select second row\n",
    "# [0] → extract scalar from array\n",
    "y = df[['lpa']].values[1][0]\n",
    "\n",
    "\n",
    "# Step 3: Forward Propagation\n",
    "# Pass input X through neural network\n",
    "# y_hat → predicted output\n",
    "# A1 → hidden layer activation (used later in backprop)\n",
    "y_hat, A1 = L_layer_forward(X, parameters)\n",
    "\n",
    "\n",
    "# Step 4: Convert prediction from array to scalar\n",
    "# Output is shape (1,1) → [[value]]\n",
    "# We extract the number for easier math operations\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "\n",
    "# Step 5: Update weights and biases\n",
    "# parameters → current weights\n",
    "# y → actual output\n",
    "# y_hat → predicted output\n",
    "# A1 → hidden layer activation\n",
    "# X → input features\n",
    "update_parameters(parameters, y, y_hat, A1, X)\n",
    "\n",
    "\n",
    "# Step 6: View updated parameters\n",
    "parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4bb8565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[6]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.4]\n",
      " [1.4]]\n",
      "****************************************\n",
      "A1:  [[1.4]\n",
      " [1.4]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.28]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.11301889 0.11735852]\n",
      " [0.11301889 0.11735852]]\n",
      "b1:  [[0.00216982]\n",
      " [0.00216982]]\n",
      "----------------------------------------\n",
      "A1:  [[1.81047206]\n",
      " [1.87990614]]\n",
      "****************************************\n",
      "A1:  [[1.81047206]\n",
      " [1.87990614]]\n",
      "W2:  [[0.124416]\n",
      " [0.124416]]\n",
      "b2:  [[0.141856]]\n",
      "----------------------------------------\n",
      "A2:  [[0.60099809]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.13122454 0.14076578]\n",
      " [0.13136168 0.14094211]]\n",
      "b1:  [[0.00477062]\n",
      " [0.00479021]]\n",
      "----------------------------------------\n",
      "A1:  [[2.10573468]\n",
      " [2.25880601]]\n",
      "****************************************\n",
      "A1:  [[2.10573468]\n",
      " [2.25880601]]\n",
      "W2:  [[0.15482832]\n",
      " [0.15599467]]\n",
      "b2:  [[0.17279267]]\n",
      "----------------------------------------\n",
      "A2:  [[0.85118173]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.1421305  0.15894239]\n",
      " [0.1424371  0.15940114]]\n",
      "b1:  [[0.00658828]\n",
      " [0.00663612]]\n",
      "----------------------------------------\n",
      "A1:  [[2.42648602]\n",
      " [2.71416177]]\n",
      "****************************************\n",
      "A1:  [[2.42648602]\n",
      " [2.71416177]]\n",
      "W2:  [[0.17651241]\n",
      " [0.17925503]]\n",
      "b2:  [[0.18955267]]\n",
      "----------------------------------------\n",
      "A2:  [[1.10438472]]\n",
      "****************************************\n",
      "Epoch -  1 Loss -  51.962560534890144\n",
      "A0:  [[6]\n",
      " [8]]\n",
      "W1:  [[0.1542238  0.18796631]\n",
      " [0.15489208 0.18929309]]\n",
      "b1:  [[0.00900694]\n",
      " [0.00912711]]\n",
      "----------------------------------------\n",
      "A1:  [[2.17348641]\n",
      " [2.65126973]]\n",
      "****************************************\n",
      "A1:  [[2.17348641]\n",
      " [2.65126973]]\n",
      "W2:  [[0.20512366]\n",
      " [0.21125834]]\n",
      "b2:  [[0.22304957]]\n",
      "----------------------------------------\n",
      "A2:  [[1.22898591]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.17650212 0.21767074]\n",
      " [0.17843494 0.22068357]]\n",
      "b1:  [[0.01272   ]\n",
      " [0.01305092]]\n",
      "----------------------------------------\n",
      "A1:  [[2.85414931]\n",
      " [3.52289823]]\n",
      "****************************************\n",
      "A1:  [[2.85414931]\n",
      " [3.52289823]]\n",
      "W2:  [[0.23890405]\n",
      " [0.25246445]]\n",
      "b2:  [[0.26800648]]\n",
      "----------------------------------------\n",
      "A2:  [[1.83928087]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.20455004 0.25373235]\n",
      " [0.20880243 0.25972749]]\n",
      "b1:  [[0.01672684]\n",
      " [0.01738914]]\n",
      "----------------------------------------\n",
      "A1:  [[3.33205142]\n",
      " [4.13705813]]\n",
      "****************************************\n",
      "A1:  [[3.33205142]\n",
      " [4.13705813]]\n",
      "W2:  [[0.27977957]\n",
      " [0.30291742]]\n",
      "b2:  [[0.31723886]]\n",
      "----------------------------------------\n",
      "A2:  [[2.50266576]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.21726997 0.27493222]\n",
      " [0.22272972 0.28293963]]\n",
      "b1:  [[0.01884683]\n",
      " [0.01971035]]\n",
      "----------------------------------------\n",
      "A1:  [[3.77795326]\n",
      " [4.78964703]]\n",
      "****************************************\n",
      "A1:  [[3.77795326]\n",
      " [4.78964703]]\n",
      "W2:  [[0.30308617]\n",
      " [0.33185477]]\n",
      "b2:  [[0.33884944]]\n",
      "----------------------------------------\n",
      "A2:  [[3.07336203]]\n",
      "****************************************\n",
      "Epoch -  2 Loss -  34.8285977479054\n",
      "A0:  [[6]\n",
      " [8]]\n",
      "W1:  [[0.23033607 0.30629087]\n",
      " [0.23723743 0.31775815]]\n",
      "b1:  [[0.02146005]\n",
      " [0.02261189]]\n",
      "----------------------------------------\n",
      "A1:  [[3.30137594]\n",
      " [4.40242233]]\n",
      "****************************************\n",
      "A1:  [[3.30137594]\n",
      " [4.40242233]]\n",
      "W2:  [[0.33275548]\n",
      " [0.36946919]]\n",
      "b2:  [[0.37732247]]\n",
      "----------------------------------------\n",
      "A2:  [[3.10243281]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.25664127 0.34136447]\n",
      " [0.26705999 0.35752156]]\n",
      "b1:  [[0.02584425]\n",
      " [0.02758232]]\n",
      "----------------------------------------\n",
      "A1:  [[4.22587309]\n",
      " [5.63482771]]\n",
      "****************************************\n",
      "A1:  [[4.22587309]\n",
      " [5.63482771]]\n",
      "W2:  [[0.37169565]\n",
      " [0.42139635]]\n",
      "b2:  [[0.43319149]]\n",
      "----------------------------------------\n",
      "A2:  [[4.37842598]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.28321802 0.37553458]\n",
      " [0.29769511 0.39690957]]\n",
      "b1:  [[0.02964093]\n",
      " [0.03195876]]\n",
      "----------------------------------------\n",
      "A1:  [[4.70590013]\n",
      " [6.25426193]]\n",
      "****************************************\n",
      "A1:  [[4.70590013]\n",
      " [6.25426193]]\n",
      "W2:  [[0.41075602]\n",
      " [0.4734799 ]]\n",
      "b2:  [[0.48272305]]\n",
      "----------------------------------------\n",
      "A2:  [[5.37696717]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.28633284 0.38072594]\n",
      " [0.30129329 0.40290655]]\n",
      "b1:  [[0.03016006]\n",
      " [0.03255846]]\n",
      "----------------------------------------\n",
      "A1:  [[5.07734378]\n",
      " [6.77106671]]\n",
      "****************************************\n",
      "A1:  [[5.07734378]\n",
      " [6.77106671]]\n",
      "W2:  [[0.41661988]\n",
      " [0.48127312]]\n",
      "b2:  [[0.48251919]]\n",
      "----------------------------------------\n",
      "A2:  [[5.85657396]]\n",
      "****************************************\n",
      "Epoch -  3 Loss -  14.45895956769712\n",
      "A0:  [[6]\n",
      " [8]]\n",
      "W1:  [[0.29122934 0.39247755]\n",
      " [0.30697335 0.41653868]]\n",
      "b1:  [[0.03113937]\n",
      " [0.03369447]]\n",
      "----------------------------------------\n",
      "A1:  [[4.23430221]\n",
      " [5.72086921]]\n",
      "****************************************\n",
      "A1:  [[4.23430221]\n",
      " [5.72086921]]\n",
      "W2:  [[0.42823102]\n",
      " [0.49675755]]\n",
      "b2:  [[0.4990444]]\n",
      "----------------------------------------\n",
      "A2:  [[5.1541889]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.31249512 0.42083193]\n",
      " [0.33192929 0.44981327]]\n",
      "b1:  [[0.03468366]\n",
      " [0.0378538 ]]\n",
      "----------------------------------------\n",
      "A1:  [[5.20951317]\n",
      " [7.03199672]]\n",
      "****************************************\n",
      "A1:  [[5.20951317]\n",
      " [7.03199672]]\n",
      "W2:  [[0.46079967]\n",
      " [0.54076031]]\n",
      "b2:  [[0.54845193]]\n",
      "----------------------------------------\n",
      "A2:  [[6.75161863]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.32773726 0.44042896]\n",
      " [0.34994634 0.47297805]]\n",
      "b1:  [[0.03686111]\n",
      " [0.04042766]]\n",
      "----------------------------------------\n",
      "A1:  [[5.50274807]\n",
      " [7.41278186]]\n",
      "****************************************\n",
      "A1:  [[5.50274807]\n",
      " [7.41278186]]\n",
      "W2:  [[0.48422561]\n",
      " [0.57238153]]\n",
      "b2:  [[0.5768783]]\n",
      "----------------------------------------\n",
      "A2:  [[7.48438931]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.3194029  0.42653836]\n",
      " [0.3401427  0.45663864]]\n",
      "b1:  [[0.03547205]\n",
      " [0.03879372]]\n",
      "----------------------------------------\n",
      "A1:  [[5.71419894]\n",
      " [7.65114924]]\n",
      "****************************************\n",
      "A1:  [[5.71419894]\n",
      " [7.65114924]]\n",
      "W2:  [[0.46788917]\n",
      " [0.55037463]]\n",
      "b2:  [[0.54740585]]\n",
      "----------------------------------------\n",
      "A2:  [[7.43201606]]\n",
      "****************************************\n",
      "Epoch -  4 Loss -  5.558882824695195\n",
      "A0:  [[6]\n",
      " [8]]\n",
      "W1:  [[0.31740288 0.4217383 ]\n",
      " [0.33779355 0.45100069]]\n",
      "b1:  [[0.03507205]\n",
      " [0.03832389]]\n",
      "----------------------------------------\n",
      "A1:  [[4.64183771]\n",
      " [6.1767592 ]]\n",
      "****************************************\n",
      "A1:  [[4.64183771]\n",
      " [6.1767592 ]]\n",
      "W2:  [[0.46295192]\n",
      " [0.54376379]]\n",
      "b2:  [[0.54289975]]\n",
      "----------------------------------------\n",
      "A2:  [[6.05054541]]\n",
      "****************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.33475748 0.44487777]\n",
      " [0.35832883 0.47838106]]\n",
      "b1:  [[0.03796448]\n",
      " [0.04174644]]\n",
      "----------------------------------------\n",
      "A1:  [[5.60622632]\n",
      " [7.4613204 ]]\n",
      "****************************************\n",
      "A1:  [[5.60622632]\n",
      " [7.4613204 ]]\n",
      "W2:  [[0.4903337 ]\n",
      " [0.58019993]]\n",
      "b2:  [[0.58609884]]\n",
      "----------------------------------------\n",
      "A2:  [[7.66407809]]\n",
      "****************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.34420829 0.45702882]\n",
      " [0.36955311 0.49281228]]\n",
      "b1:  [[0.0393146 ]\n",
      " [0.04334991]]\n",
      "----------------------------------------\n",
      "A1:  [[5.80009545]\n",
      " [7.71364558]]\n",
      "****************************************\n",
      "A1:  [[5.80009545]\n",
      " [7.71364558]]\n",
      "W2:  [[0.50531266]\n",
      " [0.60013541]]\n",
      "b2:  [[0.60280725]]\n",
      "----------------------------------------\n",
      "A2:  [[8.16290078]]\n",
      "****************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.33174421 0.43625534]\n",
      " [0.35484276 0.46829503]]\n",
      "b1:  [[0.03723725]\n",
      " [0.04089818]]\n",
      "----------------------------------------\n",
      "A1:  [[5.95407142]\n",
      " [7.84171525]]\n",
      "****************************************\n",
      "A1:  [[5.95407142]\n",
      " [7.84171525]]\n",
      "W2:  [[0.4802226 ]\n",
      " [0.56676771]]\n",
      "b2:  [[0.56244191]]\n",
      "----------------------------------------\n",
      "A2:  [[7.86615256]]\n",
      "****************************************\n",
      "Epoch -  5 Loss -  3.9780824389846035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.32767409, 0.42648705],\n",
       "        [0.35005135, 0.45679564]]),\n",
       " 'b1': array([[0.03642322],\n",
       "        [0.0399399 ]]),\n",
       " 'W2': array([[0.46990833],\n",
       "        [0.55318347]]),\n",
       " 'b2': array([[0.55145116]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 0: Initialize network parameters (weights & biases)\n",
    "# [2,2,1] → 2 input neurons, 2 hidden neurons, 1 output neuron\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "# Number of times the model will see the entire dataset\n",
    "epochs = 5\n",
    "\n",
    "# Outer loop → controls how many times we pass through the full dataset\n",
    "for i in range(epochs):\n",
    "\n",
    "  # Store loss values for all training examples in this epoch\n",
    "  Loss = []\n",
    "\n",
    "  # Inner loop → goes through each row (training example) in dataset\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    # Step 1: Extract input features for j-th training example\n",
    "    # Select 'cgpa' and 'profile_score'\n",
    "    # Convert to numpy array\n",
    "    # Pick j-th row\n",
    "    # Reshape to (features, examples) = (2,1)\n",
    "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1)\n",
    "\n",
    "    # Step 2: Extract actual output value (target)\n",
    "    # Select 'lpa' column\n",
    "    # Convert to numpy\n",
    "    # Pick j-th row\n",
    "    # Extract scalar value\n",
    "    y = df[['lpa']].values[j][0]\n",
    "\n",
    "\n",
    "    # Step 3: Forward Propagation\n",
    "    # Pass input through neural network\n",
    "    # y_hat → predicted output\n",
    "    # A1 → hidden layer activation (needed for backprop)\n",
    "    y_hat, A1 = L_layer_forward(X, parameters)\n",
    "\n",
    "    # Convert prediction from array [[value]] to scalar\n",
    "    y_hat = y_hat[0][0]\n",
    "\n",
    "\n",
    "    # Step 4: Backpropagation & Parameter Update\n",
    "    # Adjust weights based on prediction error\n",
    "    update_parameters(parameters, y, y_hat, A1, X)\n",
    "\n",
    "\n",
    "    # Step 5: Compute loss for this training example\n",
    "    # Using Mean Squared Error\n",
    "    Loss.append((y - y_hat)**2)\n",
    "\n",
    "\n",
    "  # Step 6: Print average loss after each epoch\n",
    "  print('Epoch - ', i+1, 'Loss - ', np.array(Loss).mean())\n",
    "\n",
    "\n",
    "# Final trained weights\n",
    "parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a854438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
